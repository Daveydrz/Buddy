#!/usr/bin/env python3
"""
Buddy Extraction Process Optimization Demo
Created: 2025-01-22
Purpose: Demonstrate the extraction optimization features in action
"""

import time
import threading
from datetime import datetime

def demo_extraction_optimization():
    """Demonstrate the key optimization features"""
    
    print("ğŸš€ BUDDY EXTRACTION PROCESS OPTIMIZATION DEMO")
    print("="*60)
    print("This demo shows how the optimization reduces latency and eliminates redundancy")
    print()
    
    # Import the optimized components
    try:
        from ai.extraction_coordinator import extract_with_coordination, ExtractionType, ExtractionPriority, get_extraction_coordinator
        from ai.unified_memory_manager import extract_all_from_text, extract_for_consciousness, get_memory_stats
        
        coordinator = get_extraction_coordinator()
        
        print("ğŸ¯ FEATURE 1: Context-Aware Prioritization")
        print("-" * 40)
        print("Different types of requests get different priorities:")
        
        username = "demo_user"
        
        # Simulate user interaction (CRITICAL priority)
        print("\nğŸ“¢ User says: 'I went to McDonald's with Francesco'")
        start_time = time.time()
        user_response = extract_with_coordination(
            username=username,
            text="I went to McDonald's with Francesco",
            extraction_type=ExtractionType.USER_INPUT
        )
        user_time = time.time() - start_time
        print(f"   âš¡ Processed as CRITICAL priority in {user_time:.3f}s using {user_response.tier_used}")
        
        # Simulate consciousness module (HIGH priority) 
        print("\nğŸ§  Consciousness module analyzing emotions...")
        start_time = time.time()
        consciousness_response = extract_with_coordination(
            username=username,
            text="User seems happy about social activity",
            extraction_type=ExtractionType.CONSCIOUSNESS
        )
        consciousness_time = time.time() - start_time
        print(f"   ğŸ§  Processed as HIGH priority in {consciousness_time:.3f}s using {consciousness_response.tier_used}")
        
        # Simulate background task (LOW priority)
        print("\nğŸ”„ Background memory consolidation...")
        start_time = time.time()
        background_response = extract_with_coordination(
            username=username,
            text="Consolidating user memories",
            extraction_type=ExtractionType.BACKGROUND
        )
        background_time = time.time() - start_time
        print(f"   ğŸ”„ Processed as LOW priority in {background_time:.3f}s using {background_response.tier_used}")
        
        print("\nğŸ¯ FEATURE 2: Smart Result Sharing")
        print("-" * 40)
        print("Identical requests share results to eliminate redundancy:")
        
        # First request
        print("\nğŸ“ First request: 'I had a McFlurry'")
        start_time = time.time()
        response1 = extract_with_coordination(
            username=username,
            text="I had a McFlurry",
            extraction_type=ExtractionType.USER_INPUT
        )
        time1 = time.time() - start_time
        print(f"   ğŸ“Š Processing time: {time1:.3f}s, Cache hit: {response1.cache_hit}")
        
        # Identical second request (should be cached)
        print("\nğŸ“ Identical second request: 'I had a McFlurry'")
        start_time = time.time()
        response2 = extract_with_coordination(
            username=username,
            text="I had a McFlurry",
            extraction_type=ExtractionType.USER_INPUT
        )
        time2 = time.time() - start_time
        print(f"   ğŸ“Š Processing time: {time2:.3f}s, Cache hit: {response2.cache_hit}")
        
        if response2.cache_hit:
            speedup = (time1 / time2) if time2 > 0 else float('inf')
            print(f"   ğŸš€ SPEEDUP: {speedup:.1f}x faster due to caching!")
        
        print("\nğŸ¯ FEATURE 3: Consciousness Module Coordination")
        print("-" * 40)
        print("Specialized extraction methods for different modules:")
        
        # Different consciousness modules
        modules = [
            ("emotion_engine", "User expressed happiness about social activity"),
            ("memory_fusion", "Checking for similar past experiences"),
            ("personality_tracker", "Updating social behavior patterns")
        ]
        
        for module, description in modules:
            print(f"\nğŸ§  {module}: {description}")
            start_time = time.time()
            result = extract_for_consciousness(username, description, module)
            processing_time = time.time() - start_time
            print(f"   âš¡ Processed in {processing_time:.3f}s with context-aware optimization")
        
        print("\nğŸ¯ FEATURE 4: Performance Metrics")
        print("-" * 40)
        
        # Get performance metrics
        metrics = coordinator.get_performance_metrics()
        stats = get_memory_stats()
        
        print("ğŸ“Š Extraction Coordinator Metrics:")
        print(f"   â€¢ Total requests: {metrics['total_requests']}")
        print(f"   â€¢ Cache hit rate: {metrics['cache_hit_rate_percent']:.1f}%")
        print(f"   â€¢ Average processing time: {metrics['average_processing_time']:.3f}s")
        print(f"   â€¢ TIER 1 extractions: {metrics['tier1_extractions']} (fast)")
        print(f"   â€¢ TIER 2 extractions: {metrics['tier2_extractions']} (medium)")
        print(f"   â€¢ TIER 3 extractions: {metrics['tier3_extractions']} (comprehensive)")
        
        print("\nğŸ“Š Memory System Stats:")
        print(f"   â€¢ Active users: {stats['active_users']}")
        print(f"   â€¢ Cached extractions: {stats['cached_extractions']}")
        print(f"   â€¢ Active extractors: {len(stats['user_list'])}")
        
        print("\nğŸ¯ FEATURE 5: Context-Aware Processing")
        print("-" * 40)
        print("Smart filtering prevents unnecessary extractions:")
        
        # Test context awareness
        test_cases = [
            ("Hello", "Should be filtered as casual"),
            ("I went to McDonald's", "Should be processed (contains meaningful content)"),
            ("ok", "Should be filtered as acknowledgment"),
            ("I had a McFlurry", "Should enhance existing McDonald's memory")
        ]
        
        for text, description in test_cases:
            print(f"\nğŸ’¬ '{text}' - {description}")
            result = extract_all_from_text(username, text)
            
            if result.intent_classification == "casual_conversation":
                print("   ğŸš« Filtered out - no unnecessary processing")
            elif result.intent_classification == "memory_enhancement":
                print("   ğŸ”— Enhanced existing memory thread")
            else:
                print(f"   âœ… Processed - {len(result.memory_events)} events extracted")
        
        print("\nğŸ¯ SUMMARY: Optimization Benefits")
        print("-" * 40)
        print("âœ… Context-aware prioritization reduces response latency")
        print("âœ… Smart caching eliminates redundant KoboldCPP calls")
        print("âœ… Consciousness module coordination prevents conflicts")
        print("âœ… Enhanced filtering reduces unnecessary processing")
        print("âœ… Connection optimization handles resource contention")
        print("âœ… All Class 5+ consciousness capabilities preserved")
        
        cache_hit_rate = metrics['cache_hit_rate_percent']
        if cache_hit_rate > 0:
            print(f"\nğŸš€ Current session achieved {cache_hit_rate:.1f}% cache hit rate!")
            print("ğŸ’¡ In real usage, this translates to significantly faster responses")
        
        print("\n" + "="*60)
        print("ğŸ‰ DEMO COMPLETE - Buddy's extraction processes are now optimized!")
        
    except Exception as e:
        print(f"âŒ Demo failed: {e}")
        import traceback
        traceback.print_exc()

def demo_concurrent_optimization():
    """Demonstrate coordination of concurrent requests"""
    
    print("\n\nğŸ”„ CONCURRENT REQUEST COORDINATION DEMO")
    print("="*50)
    print("Simulating multiple simultaneous extraction requests...")
    
    try:
        from ai.extraction_coordinator import extract_with_coordination, ExtractionType
        
        username = "concurrent_demo_user"
        results = []
        
        def make_concurrent_request(request_id, delay=0):
            """Make a concurrent extraction request"""
            if delay:
                time.sleep(delay)
            
            start_time = time.time()
            response = extract_with_coordination(
                username=username,
                text=f"Processing request {request_id} - I went to McDonald's",
                extraction_type=ExtractionType.USER_INPUT
            )
            processing_time = time.time() - start_time
            
            results.append({
                'id': request_id,
                'time': processing_time,
                'cache_hit': response.cache_hit,
                'tier': response.tier_used
            })
            
            status = "ğŸš€ Cache HIT" if response.cache_hit else "ğŸ“ Processed"
            print(f"   Request {request_id}: {processing_time:.3f}s ({status})")
        
        # Launch concurrent requests
        print("ğŸš€ Launching 5 concurrent requests...")
        threads = []
        
        for i in range(5):
            thread = threading.Thread(target=make_concurrent_request, args=(i+1, i*0.1))
            threads.append(thread)
            thread.start()
        
        # Wait for completion
        for thread in threads:
            thread.join()
        
        # Analyze results
        print(f"\nğŸ“Š Results from {len(results)} concurrent requests:")
        
        cache_hits = sum(1 for r in results if r['cache_hit'])
        avg_time = sum(r['time'] for r in results) / len(results)
        
        print(f"   â€¢ Cache hits: {cache_hits}/{len(results)} ({cache_hits/len(results)*100:.1f}%)")
        print(f"   â€¢ Average time: {avg_time:.3f}s")
        print(f"   â€¢ Fastest request: {min(r['time'] for r in results):.3f}s")
        print(f"   â€¢ Slowest request: {max(r['time'] for r in results):.3f}s")
        
        if cache_hits > 0:
            print("\nâœ… Coordination working: Later requests benefited from caching!")
            print("ğŸ’¡ This eliminates redundant processing during high-activity periods")
        
    except Exception as e:
        print(f"âŒ Concurrent demo failed: {e}")

if __name__ == "__main__":
    # Run the main demo
    demo_extraction_optimization()
    
    # Run concurrent demo
    demo_concurrent_optimization()
    
    print("\nğŸ¯ Ready for production: The Buddy system is now optimized for:")
    print("   â€¢ Faster response times between user questions and answers")
    print("   â€¢ Reduced KoboldCPP resource contention") 
    print("   â€¢ Eliminated redundant memory operations")
    print("   â€¢ Context-aware processing that preserves Class 5+ consciousness")
    print("   â€¢ Robust error handling and recovery mechanisms")